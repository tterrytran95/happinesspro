{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "wired-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-memphis",
   "metadata": {},
   "source": [
    "## In this notebook, we'll guarantee that all the countries are uniform between 2015-2020 dataframes.\n",
    "- This is a preprocessing notebook where all the data will be modified such that there is a 1-1 mapping between countries of each dataframe.\n",
    "- Use 2020 as our standard because want to predict this year\n",
    "- Remove countries from 2015-2019 that are NOT in 2020\n",
    "- [Drop data](https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "great-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframes/df2015', 'rb') as f_2015:\n",
    "    df2015 = pickle.load(f_2015)\n",
    "f_2015.close()\n",
    "\n",
    "with open('dataframes/df2016', 'rb') as f_2016:\n",
    "    df2016 = pickle.load(f_2016)\n",
    "f_2016.close()\n",
    "\n",
    "with open('dataframes/df2017', 'rb') as f_2017:\n",
    "    df2017 = pickle.load(f_2017)\n",
    "f_2017.close()\n",
    "\n",
    "with open('dataframes/df2018', 'rb') as f_2018:\n",
    "    df2018 = pickle.load(f_2018)\n",
    "f_2018.close()\n",
    "\n",
    "with open('dataframes/df2019', 'rb') as f_2019:\n",
    "    df2019 = pickle.load(f_2019)\n",
    "f_2019.close()\n",
    "\n",
    "with open('dataframes/df2020', 'rb') as f_2020:\n",
    "    df2020 = pickle.load(f_2020)\n",
    "f_2020.close()\n",
    "\n",
    "with open('dataframes/df_all', 'rb') as f_all:\n",
    "    df_all = pickle.load(f_all)\n",
    "f_all.close()\n",
    "\n",
    "with open('dataframes/df_feats', 'rb') as f_feats:\n",
    "    df_feats = pickle.load(f_feats)\n",
    "f_feats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "exterior-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_2020 = df2020['Country or region'].tolist()\n",
    "# c_2019 = df2019['Country or region'].tolist()\n",
    "# c_2018 = df2018['Country or region'].tolist()\n",
    "# c_2017 = df2017['Country or region'].tolist()\n",
    "# c_2016 = df2016['Country or region'].tolist()\n",
    "# c_2015 = df2015['Country or region'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-teens",
   "metadata": {},
   "source": [
    "## Remove countries not found in 2020 \n",
    "- Not considering countries that are spelled differently across df's (United States and Hong Kong)\n",
    "- Start from 2020, move back towards 2015 and remove countries not found in next year's dataframe.\n",
    "- Once all the countries have been removed from previous years, we will do the same starting from 2015 towards 2020.\n",
    "- This will remove countries in 2016..2020 based on the years before.\n",
    "- After this, we will have the intersection of all countries across 5 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "heated-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "Taiwan\n",
      "Qatar\n",
      "Trinidad & Tobago\n",
      "Northern Cyprus\n",
      "Hong Kong\n",
      "North Macedonia\n",
      "Bhutan\n",
      "Somalia\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[18, 24, 28, 38, 63, 75, 83, 94, 111, 148]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2019\n",
    "c_2020 = df2020['Country or region'].tolist()\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2019)):\n",
    "    if (c_2019[i] not in c_2020):\n",
    "        drop_index.append(i)\n",
    "        print(c_2019[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "surrounded-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019.drop(df2019.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "higher-truth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "Taiwan\n",
      "Qatar\n",
      "Trinidad & Tobago\n",
      "Belize\n",
      "Northern Cyprus\n",
      "Hong Kong\n",
      "Macedonia\n",
      "Bhutan\n",
      "Somalia\n",
      "Sudan\n",
      "Angola\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17, 25, 31, 37, 48, 57, 75, 88, 96, 97, 136, 141, 149]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2018\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2018)):\n",
    "    if (c_2018[i] not in c_2019):\n",
    "        drop_index.append(i)\n",
    "        print(c_2018[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "positive-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.drop(df2018.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "sexual-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "Taiwan Province of China\n",
      "Qatar\n",
      "Trinidad and Tobago\n",
      "Belize\n",
      "North Cyprus\n",
      "Hong Kong S.A.R., China\n",
      "Macedonia\n",
      "Somalia\n",
      "Bhutan\n",
      "Sudan\n",
      "Angola\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13, 32, 34, 37, 49, 60, 70, 91, 92, 96, 129, 139, 151]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2017\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2017)):\n",
    "    if (c_2017[i] not in c_2018):\n",
    "        drop_index.append(i)\n",
    "        print(c_2017[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "allied-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017.drop(df2017.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "sensitive-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "Puerto Rico\n",
      "Taiwan\n",
      "Qatar\n",
      "Suriname\n",
      "Trinidad and Tobago\n",
      "Belize\n",
      "North Cyprus\n",
      "Hong Kong\n",
      "Somalia\n",
      "Bhutan\n",
      "Macedonia\n",
      "Somaliland Region\n",
      "Laos\n",
      "Sudan\n",
      "Comoros\n",
      "Angola\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12, 14, 34, 35, 39, 42, 51, 61, 74, 75, 83, 94, 96, 101, 132, 137, 140, 155]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2016\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2016)):\n",
    "    if (c_2016[i] not in c_2017):\n",
    "        drop_index.append(i)\n",
    "        print(c_2016[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "interim-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016.drop(df2016.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "loving-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "Oman\n",
      "Qatar\n",
      "Taiwan\n",
      "Suriname\n",
      "Trinidad and Tobago\n",
      "North Cyprus\n",
      "Hong Kong\n",
      "Bhutan\n",
      "Somaliland region\n",
      "Macedonia\n",
      "Mozambique\n",
      "Lesotho\n",
      "Laos\n",
      "Swaziland\n",
      "Sudan\n",
      "Djibouti\n",
      "Angola\n",
      "Comoros\n",
      "Central African Republic\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 21,\n",
       " 27,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 65,\n",
       " 71,\n",
       " 78,\n",
       " 90,\n",
       " 92,\n",
       " 93,\n",
       " 96,\n",
       " 98,\n",
       " 100,\n",
       " 117,\n",
       " 125,\n",
       " 136,\n",
       " 139,\n",
       " 147,\n",
       " 155]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2015\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "c_2015 = df2015['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2015)):\n",
    "    if (c_2015[i] not in c_2016):\n",
    "        drop_index.append(i)\n",
    "        print(c_2015[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fatty-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015.drop(df2015.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "small-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 10)\n",
      "(146, 10)\n",
      "(143, 10)\n",
      "(142, 10)\n",
      "(139, 10)\n",
      "(137, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df2020.shape)\n",
    "print(df2019.shape)\n",
    "print(df2018.shape)\n",
    "print(df2017.shape)\n",
    "print(df2016.shape)\n",
    "print(df2015.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "quantitative-calibration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98, 125]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2016\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "c_2015 = df2015['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2016)):\n",
    "    if (c_2016[i] not in c_2015):\n",
    "        drop_index.append(i)\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "treated-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016.drop(df2016.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "mechanical-matthew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namibia\n",
      "Mozambique\n",
      "Lesotho\n",
      "South Sudan\n",
      "Central African Republic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[100, 102, 127, 134, 141]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2017\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2017)):\n",
    "    if (c_2017[i] not in c_2016):\n",
    "        drop_index.append(i)\n",
    "        print(c_2017[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "sublime-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017.drop(df2017.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "modern-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laos\n",
      "Namibia\n",
      "Mozambique\n",
      "Lesotho\n",
      "South Sudan\n",
      "Central African Republic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[99, 108, 112, 129, 140, 141]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2018\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2018)):\n",
    "    if (c_2018[i] not in c_2017):\n",
    "        drop_index.append(i)\n",
    "        print(c_2018[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "standard-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.drop(df2018.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fuzzy-integral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laos\n",
      "Namibia\n",
      "Gambia\n",
      "Mozambique\n",
      "Swaziland\n",
      "Comoros\n",
      "Lesotho\n",
      "Central African Republic\n",
      "South Sudan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[96, 103, 110, 113, 125, 132, 134, 144, 145]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2019\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2019)):\n",
    "    if (c_2019[i] not in c_2018):\n",
    "        drop_index.append(i)\n",
    "        print(c_2019[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "golden-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019.drop(df2019.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "protecting-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States of America\n",
      "Taiwan Province of China\n",
      "Trinidad and Tobago\n",
      "North Cyprus\n",
      "Hong Kong S.A.R. of China\n",
      "Maldives\n",
      "Macedonia\n",
      "Laos\n",
      "Gambia\n",
      "Mozambique\n",
      "Namibia\n",
      "Swaziland\n",
      "Comoros\n",
      "Lesotho\n",
      "Central African Republic\n",
      "South Sudan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17, 24, 41, 75, 77, 86, 89, 103, 112, 119, 121, 131, 133, 142, 148, 151]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2020\n",
    "c_2020 = df2020['Country or region'].tolist()\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2020)):\n",
    "    if (c_2020[i] not in c_2019):\n",
    "        drop_index.append(i)\n",
    "        print(c_2020[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "general-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020.drop(df2020.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "separated-tender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 10)\n",
      "(137, 10)\n",
      "(137, 10)\n",
      "(137, 10)\n",
      "(137, 10)\n",
      "(137, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df2020.shape)\n",
    "print(df2019.shape)\n",
    "print(df2018.shape)\n",
    "print(df2017.shape)\n",
    "print(df2016.shape)\n",
    "print(df2015.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "unique-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2015', 'wb')\n",
    "pickle.dump(df2015, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "executive-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2016', 'wb')\n",
    "pickle.dump(df2016, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "noticed-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2017', 'wb')\n",
    "pickle.dump(df2017, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "prescription-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2018', 'wb')\n",
    "pickle.dump(df2018, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "painful-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2019', 'wb')\n",
    "pickle.dump(df2019, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "brutal-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2020', 'wb')\n",
    "pickle.dump(df2020, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-block",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-connecticut",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
