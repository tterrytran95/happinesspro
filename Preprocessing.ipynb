{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "wired-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-memphis",
   "metadata": {},
   "source": [
    "## In this notebook, we'll guarantee that all the countries are uniform between 2015-2020 dataframes.\n",
    "- This is a preprocessing notebook where all the data will be modified such that there is a 1-1 mapping between countries of each dataframe.\n",
    "- Use 2020 as our standard because want to predict this year\n",
    "- Remove countries from 2015-2019 that are NOT in 2020\n",
    "- [Drop data](https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "great-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframes/df2015', 'rb') as f_2015:\n",
    "    df2015 = pickle.load(f_2015)\n",
    "f_2015.close()\n",
    "\n",
    "with open('dataframes/df2016', 'rb') as f_2016:\n",
    "    df2016 = pickle.load(f_2016)\n",
    "f_2016.close()\n",
    "\n",
    "with open('dataframes/df2017', 'rb') as f_2017:\n",
    "    df2017 = pickle.load(f_2017)\n",
    "f_2017.close()\n",
    "\n",
    "with open('dataframes/df2018', 'rb') as f_2018:\n",
    "    df2018 = pickle.load(f_2018)\n",
    "f_2018.close()\n",
    "\n",
    "with open('dataframes/df2019', 'rb') as f_2019:\n",
    "    df2019 = pickle.load(f_2019)\n",
    "f_2019.close()\n",
    "\n",
    "with open('dataframes/df2020', 'rb') as f_2020:\n",
    "    df2020 = pickle.load(f_2020)\n",
    "f_2020.close()\n",
    "\n",
    "with open('dataframes/df_all', 'rb') as f_all:\n",
    "    df_all = pickle.load(f_all)\n",
    "f_all.close()\n",
    "\n",
    "with open('dataframes/df_feats', 'rb') as f_feats:\n",
    "    df_feats = pickle.load(f_feats)\n",
    "f_feats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "exterior-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_2020 = df2020['Country or region'].tolist()\n",
    "# c_2019 = df2019['Country or region'].tolist()\n",
    "# c_2018 = df2018['Country or region'].tolist()\n",
    "# c_2017 = df2017['Country or region'].tolist()\n",
    "# c_2016 = df2016['Country or region'].tolist()\n",
    "# c_2015 = df2015['Country or region'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-collective",
   "metadata": {},
   "source": [
    "## Remove countries not found in 2020 \n",
    "- Not considering countries that are spelled differently across df's (United States and Hong Kong)\n",
    "- Start from 2020, move back towards 2015 and remove countries not found in next year's dataframe.\n",
    "- Once all the countries have been removed from previous years, we will do the same starting from 2015 towards 2020.\n",
    "- This will remove countries in 2016..2020 based on the years before.\n",
    "- After this, we will have the intersection of all countries across 5 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "rational-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gotta fix something about 2020 first \n",
    "for index in df2020.index:\n",
    "    if df2020.loc[index,'Country or region']=='United States of America':\n",
    "        df2020.loc[index,'Country or region'] = 'United States'\n",
    "#     elif df2020.loc[index,'Country or region']=='S Sudan':\n",
    "#         df2020.loc[index,'Country or region'] = 'Sudan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "heated-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan\n",
      "Qatar\n",
      "Trinidad & Tobago\n",
      "Northern Cyprus\n",
      "Hong Kong\n",
      "North Macedonia\n",
      "Bhutan\n",
      "Somalia\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24, 28, 38, 63, 75, 83, 94, 111, 148]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2019\n",
    "c_2020 = df2020['Country or region'].tolist()\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2019)):\n",
    "    if (c_2019[i] not in c_2020):\n",
    "        drop_index.append(i)\n",
    "        print(c_2019[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "surrounded-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019.drop(df2019.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "higher-truth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan\n",
      "Qatar\n",
      "Trinidad & Tobago\n",
      "Belize\n",
      "Northern Cyprus\n",
      "Hong Kong\n",
      "Macedonia\n",
      "Bhutan\n",
      "Somalia\n",
      "Sudan\n",
      "Angola\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[25, 31, 37, 48, 57, 75, 88, 96, 97, 136, 141, 149]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2018\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2018)):\n",
    "    if (c_2018[i] not in c_2019):\n",
    "        drop_index.append(i)\n",
    "        print(c_2018[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "positive-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.drop(df2018.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "sexual-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan Province of China\n",
      "Qatar\n",
      "Trinidad and Tobago\n",
      "Belize\n",
      "North Cyprus\n",
      "Hong Kong S.A.R., China\n",
      "Macedonia\n",
      "Somalia\n",
      "Bhutan\n",
      "Sudan\n",
      "Angola\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[32, 34, 37, 49, 60, 70, 91, 92, 96, 129, 139, 151]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2017\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2017)):\n",
    "    if (c_2017[i] not in c_2018):\n",
    "        drop_index.append(i)\n",
    "        print(c_2017[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "allied-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017.drop(df2017.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "sensitive-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puerto Rico\n",
      "Taiwan\n",
      "Qatar\n",
      "Suriname\n",
      "Trinidad and Tobago\n",
      "Belize\n",
      "North Cyprus\n",
      "Hong Kong\n",
      "Somalia\n",
      "Bhutan\n",
      "Macedonia\n",
      "Somaliland Region\n",
      "Laos\n",
      "Sudan\n",
      "Comoros\n",
      "Angola\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14, 34, 35, 39, 42, 51, 61, 74, 75, 83, 94, 96, 101, 132, 137, 140, 155]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2016\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2016)):\n",
    "    if (c_2016[i] not in c_2017):\n",
    "        drop_index.append(i)\n",
    "        print(c_2016[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "interim-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016.drop(df2016.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "loving-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oman\n",
      "Qatar\n",
      "Taiwan\n",
      "Suriname\n",
      "Trinidad and Tobago\n",
      "North Cyprus\n",
      "Hong Kong\n",
      "Bhutan\n",
      "Somaliland region\n",
      "Macedonia\n",
      "Mozambique\n",
      "Lesotho\n",
      "Laos\n",
      "Swaziland\n",
      "Sudan\n",
      "Djibouti\n",
      "Angola\n",
      "Comoros\n",
      "Central African Republic\n",
      "Syria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21,\n",
       " 27,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 65,\n",
       " 71,\n",
       " 78,\n",
       " 90,\n",
       " 92,\n",
       " 93,\n",
       " 96,\n",
       " 98,\n",
       " 100,\n",
       " 117,\n",
       " 125,\n",
       " 136,\n",
       " 139,\n",
       " 147,\n",
       " 155]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2015\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "c_2015 = df2015['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2015)):\n",
    "    if (c_2015[i] not in c_2016):\n",
    "        drop_index.append(i)\n",
    "        print(c_2015[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "fatty-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015.drop(df2015.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "small-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 10)\n",
      "(147, 10)\n",
      "(144, 10)\n",
      "(143, 10)\n",
      "(140, 10)\n",
      "(138, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df2020.shape)\n",
    "print(df2019.shape)\n",
    "print(df2018.shape)\n",
    "print(df2017.shape)\n",
    "print(df2016.shape)\n",
    "print(df2015.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "expired-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99, 126]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2016\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "c_2015 = df2015['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2016)):\n",
    "    if (c_2016[i] not in c_2015):\n",
    "        drop_index.append(i)\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "sapphire-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016.drop(df2016.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "sporting-transition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namibia\n",
      "Mozambique\n",
      "Lesotho\n",
      "South Sudan\n",
      "Central African Republic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[101, 103, 128, 135, 142]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2017\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "c_2016 = df2016['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2017)):\n",
    "    if (c_2017[i] not in c_2016):\n",
    "        drop_index.append(i)\n",
    "        print(c_2017[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "minimal-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017.drop(df2017.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "analyzed-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laos\n",
      "Namibia\n",
      "Mozambique\n",
      "Lesotho\n",
      "South Sudan\n",
      "Central African Republic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[100, 109, 113, 130, 141, 142]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2018\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "c_2017 = df2017['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2018)):\n",
    "    if (c_2018[i] not in c_2017):\n",
    "        drop_index.append(i)\n",
    "        print(c_2018[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "amended-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.drop(df2018.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "removed-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laos\n",
      "Namibia\n",
      "Gambia\n",
      "Mozambique\n",
      "Swaziland\n",
      "Comoros\n",
      "Lesotho\n",
      "Central African Republic\n",
      "South Sudan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[97, 104, 111, 114, 126, 133, 135, 145, 146]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2019\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "c_2018 = df2018['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2019)):\n",
    "    if (c_2019[i] not in c_2018):\n",
    "        drop_index.append(i)\n",
    "        print(c_2019[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "artificial-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019.drop(df2019.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "least-paper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taiwan Province of China\n",
      "Trinidad and Tobago\n",
      "North Cyprus\n",
      "Hong Kong S.A.R. of China\n",
      "Maldives\n",
      "Macedonia\n",
      "Laos\n",
      "Gambia\n",
      "Mozambique\n",
      "Namibia\n",
      "Swaziland\n",
      "Comoros\n",
      "Lesotho\n",
      "Central African Republic\n",
      "South Sudan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[24, 41, 75, 77, 86, 89, 103, 112, 119, 121, 131, 133, 142, 148, 151]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 2020\n",
    "c_2020 = df2020['Country or region'].tolist()\n",
    "c_2019 = df2019['Country or region'].tolist()\n",
    "drop_index = [] # list of rows to drop by index \n",
    "for i in range(len(c_2020)):\n",
    "    if (c_2020[i] not in c_2019):\n",
    "        drop_index.append(i)\n",
    "        print(c_2020[i])\n",
    "drop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "starting-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020.drop(df2020.index[drop_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "metallic-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 10)\n",
      "(138, 10)\n",
      "(138, 10)\n",
      "(138, 10)\n",
      "(138, 10)\n",
      "(138, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df2020.shape)\n",
    "print(df2019.shape)\n",
    "print(df2018.shape)\n",
    "print(df2017.shape)\n",
    "print(df2016.shape)\n",
    "print(df2015.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "outdoor-roulette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df2020['Country or region']) == set(df2019['Country or region'].tolist()) == set(df2018['Country or region'].tolist()) == set(df2017['Country or region'].tolist()) == set(df2016['Country or region'].tolist()) == set(df2015['Country or region'].tolist())\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "touched-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2015', 'wb')\n",
    "pickle.dump(df2015, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "partial-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2016', 'wb')\n",
    "pickle.dump(df2016, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "indian-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2017', 'wb')\n",
    "pickle.dump(df2017, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "accredited-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2018', 'wb')\n",
    "pickle.dump(df2018, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "current-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2019', 'wb')\n",
    "pickle.dump(df2019, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "elementary-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('dataframes/df2020', 'wb')\n",
    "pickle.dump(df2020, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-ancient",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
