{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "instrumental-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "improved-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataframes/df2015', 'rb') as f_2015:\n",
    "    df2015 = pickle.load(f_2015)\n",
    "f_2015.close()\n",
    "\n",
    "with open('dataframes/df2016', 'rb') as f_2016:\n",
    "    df2016 = pickle.load(f_2016)\n",
    "f_2016.close()\n",
    "\n",
    "with open('dataframes/df2017', 'rb') as f_2017:\n",
    "    df2017 = pickle.load(f_2017)\n",
    "f_2017.close()\n",
    "\n",
    "with open('dataframes/df2018', 'rb') as f_2018:\n",
    "    df2018 = pickle.load(f_2018)\n",
    "f_2018.close()\n",
    "\n",
    "with open('dataframes/df2019', 'rb') as f_2019:\n",
    "    df2019 = pickle.load(f_2019)\n",
    "f_2019.close()\n",
    "\n",
    "with open('dataframes/df2020', 'rb') as f_2020:\n",
    "    df2020 = pickle.load(f_2020)\n",
    "f_2020.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-mineral",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- The data in this set lends itself to linear regression since the happiness score is positively correlated with all its features as seen in the EDA steps. \n",
    "- GDP is the highest correlated features. \n",
    "- Since there are only 7 features, it's likely that we won't need to perform PCA on the dataset since there is no worthy feature to remove. These have all been engineered to be linearly correlated with our target (happiness). \n",
    "- Here, we will explore different ways regression can be applied to this dataset to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-configuration",
   "metadata": {},
   "source": [
    "### Question 1: What is the happines score of each country for 2020 given the 2020 features?\n",
    "- we predicted for MOST countries based on SOME countries for this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "chicken-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2020['Score'] # target \n",
    "X = df2020.iloc[:, 1:].drop(['Score'],axis='columns') # features \n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=.2)\n",
    "# print(train_x.shape)\n",
    "# print(test_y.shape) # ok! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "eastern-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x.iloc[:, 1:])\n",
    "test_x = scaler.transform(test_x.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "gentle-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(train_x, train_y) # keep the countries # index without it \n",
    "hyp = lr_reg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "northern-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...          \t 0.9677902169395654\n",
      "Variance explained...\t 0.9679045293192847\n",
      "Mean squared error...\t 0.024234444966055584\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "res = test_y - hyp\n",
    "r2 = r2_score(test_y, hyp)\n",
    "var = explained_variance_score(test_y, hyp)\n",
    "mse = mean_squared_error(test_y, hyp)\n",
    "print('R2 score...          \\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-cornwall",
   "metadata": {},
   "source": [
    "### Question 2: What is the happiness score of each country for 2020 given the the data from past years (2015-2019)?\n",
    "- This is kind of a hot mess\n",
    "- See how Ariana does this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "optimum-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_feats['Score'] # target \n",
    "X = df_feats.iloc[:, 1:].drop(['Score'],axis='columns') # features \n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=.2)\n",
    "# print(train_x.shape)\n",
    "# print(test_y.shape) # ok! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "wireless-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# train_x = scaler.fit_transform(train_x.iloc[:, 1:])\n",
    "# test_x = scaler.fit(test_x.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "varying-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_reg = LinearRegression()\n",
    "# lr_reg = GridSearchCV(lr, param_grid={}, n_jobs = 5)\n",
    "# lr_reg.fit(train_x.iloc[:, 2:], train_y) # keep the countries # index without it \n",
    "# hyp = lr_reg.predict(test_x.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "local-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_score = r2_score(test_y, hyp)\n",
    "# var = explained_variance_score(test_y, hyp)\n",
    "# mse = mean_squared_error(test_y, hyp)\n",
    "# print('R2 score...\\t', r2_score)\n",
    "# print('Variance explained...\\t', var)\n",
    "# print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-variety",
   "metadata": {},
   "source": [
    "### Question 3: Given that we predict the each feature for 2020, can we obtain a valid happiness score?\n",
    "- We will predict the GDP for 2020 given 2015-2019, Health Life Expectancy for 2020 given 2015-2019, etc. \n",
    "- Once those features are predicted, we will predict the happiness score! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-collect",
   "metadata": {},
   "source": [
    "### Preliminary preprocessing\n",
    "- Fill na\n",
    "- Encode countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "martial-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all features (2015-2019) together\n",
    "df_all = pd.concat([df2015, df2016, df2017, df2018, df2019])\n",
    "df_all[df_all['Perceptions of corruption'].isna()] # one null value \n",
    "mean = df_all[df_all['Country or region'] == 'United Arab Emirates']['Perceptions of corruption'].mean() # get avg \n",
    "df_all = df_all.fillna(mean) # fill na with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "electoral-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode countries\n",
    "ohe = OneHotEncoder()\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "funded-elevation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Country or region</th>\n",
       "      <th>Overall rank</th>\n",
       "      <th>Score</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>Generosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.29678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>2</td>\n",
       "      <td>7.561</td>\n",
       "      <td>1.30232</td>\n",
       "      <td>1.40223</td>\n",
       "      <td>0.94784</td>\n",
       "      <td>0.62877</td>\n",
       "      <td>0.14145</td>\n",
       "      <td>0.43630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.34139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>Norway</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.34699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>Canada</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.45811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2019</td>\n",
       "      <td>Malawi</td>\n",
       "      <td>150</td>\n",
       "      <td>3.410</td>\n",
       "      <td>0.19100</td>\n",
       "      <td>0.56000</td>\n",
       "      <td>0.49500</td>\n",
       "      <td>0.44300</td>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.21800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2019</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>151</td>\n",
       "      <td>3.380</td>\n",
       "      <td>0.28700</td>\n",
       "      <td>1.16300</td>\n",
       "      <td>0.46300</td>\n",
       "      <td>0.14300</td>\n",
       "      <td>0.07700</td>\n",
       "      <td>0.10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2019</td>\n",
       "      <td>Rwanda</td>\n",
       "      <td>152</td>\n",
       "      <td>3.334</td>\n",
       "      <td>0.35900</td>\n",
       "      <td>0.71100</td>\n",
       "      <td>0.61400</td>\n",
       "      <td>0.55500</td>\n",
       "      <td>0.41100</td>\n",
       "      <td>0.21700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>153</td>\n",
       "      <td>3.231</td>\n",
       "      <td>0.47600</td>\n",
       "      <td>0.88500</td>\n",
       "      <td>0.49900</td>\n",
       "      <td>0.41700</td>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.27600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2019</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>154</td>\n",
       "      <td>3.203</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>0.51700</td>\n",
       "      <td>0.36100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.15800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year Country or region  Overall rank  Score  GDP per capita  \\\n",
       "0    2015       Switzerland             1  7.587         1.39651   \n",
       "1    2015           Iceland             2  7.561         1.30232   \n",
       "2    2015           Denmark             3  7.527         1.32548   \n",
       "3    2015            Norway             4  7.522         1.45900   \n",
       "4    2015            Canada             5  7.427         1.32629   \n",
       "..    ...               ...           ...    ...             ...   \n",
       "149  2019            Malawi           150  3.410         0.19100   \n",
       "150  2019             Yemen           151  3.380         0.28700   \n",
       "151  2019            Rwanda           152  3.334         0.35900   \n",
       "152  2019          Tanzania           153  3.231         0.47600   \n",
       "153  2019       Afghanistan           154  3.203         0.35000   \n",
       "\n",
       "     Social support  Healthy life expectancy  Freedom  \\\n",
       "0           1.34951                  0.94143  0.66557   \n",
       "1           1.40223                  0.94784  0.62877   \n",
       "2           1.36058                  0.87464  0.64938   \n",
       "3           1.33095                  0.88521  0.66973   \n",
       "4           1.32261                  0.90563  0.63297   \n",
       "..              ...                      ...      ...   \n",
       "149         0.56000                  0.49500  0.44300   \n",
       "150         1.16300                  0.46300  0.14300   \n",
       "151         0.71100                  0.61400  0.55500   \n",
       "152         0.88500                  0.49900  0.41700   \n",
       "153         0.51700                  0.36100  0.00000   \n",
       "\n",
       "     Perceptions of corruption  Generosity  \n",
       "0                      0.41978     0.29678  \n",
       "1                      0.14145     0.43630  \n",
       "2                      0.48357     0.34139  \n",
       "3                      0.36503     0.34699  \n",
       "4                      0.32957     0.45811  \n",
       "..                         ...         ...  \n",
       "149                    0.08900     0.21800  \n",
       "150                    0.07700     0.10800  \n",
       "151                    0.41100     0.21700  \n",
       "152                    0.14700     0.27600  \n",
       "153                    0.02500     0.15800  \n",
       "\n",
       "[685 rows x 10 columns]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-catering",
   "metadata": {},
   "source": [
    "### GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "speaking-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_all['GDP per capita'].to_numpy()\n",
    "train_x = df_all.iloc[:, 5:]\n",
    "test_y = df2020['GDP per capita'].to_numpy()\n",
    "test_x = df2020.iloc[:, 4:9]\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "utility-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "hyp_gdp = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "clear-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...\t 0.3945308607083984\n",
      "Variance explained...\t 0.7075677218115671\n",
      "Mean squared error...\t 0.07888287353495015\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_y, hyp_gdp)\n",
    "var = explained_variance_score(test_y, hyp_gdp)\n",
    "mse = mean_squared_error(test_y, hyp_gdp)\n",
    "print('R2 score...\\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-cycling",
   "metadata": {},
   "source": [
    "### Healthy Life Exptectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "invalid-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_all['Healthy life expectancy'].to_numpy()\n",
    "train_x = df_all.drop(columns=['Healthy life expectancy']).iloc[:, 4:]\n",
    "test_y = df2020['Healthy life expectancy'].to_numpy()\n",
    "test_x = df2020.drop(columns=['Healthy life expectancy']).iloc[:, 3:8]\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "handy-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "hyp_hle = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "irish-paris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...\t 0.6010243371199526\n",
      "Variance explained...\t 0.7332283890756466\n",
      "Mean squared error...\t 0.022183520464343288\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_y, hyp_hle)\n",
    "var = explained_variance_score(test_y, hyp_hle)\n",
    "mse = mean_squared_error(test_y, hyp_hle)\n",
    "print('R2 score...\\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-extent",
   "metadata": {},
   "source": [
    "### Social support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "selective-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_all['Social support'].to_numpy()\n",
    "train_x = df_all.drop(columns=['Social support']).iloc[:, 4:]\n",
    "test_y = df2020['Social support'].to_numpy()\n",
    "test_x = df2020.drop(columns=['Social support']).iloc[:, 3:8]\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "consistent-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "hyp_ss = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "prerequisite-hacker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...\t 0.571364047938336\n",
      "Variance explained...\t 0.5909787714362185\n",
      "Mean squared error...\t 0.031910509966876936\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_y, hyp_ss)\n",
    "var = explained_variance_score(test_y, hyp_ss)\n",
    "mse = mean_squared_error(test_y, hyp_ss)\n",
    "print('R2 score...\\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-economy",
   "metadata": {},
   "source": [
    "### Freedom to make life choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "cheap-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_all['Freedom'].to_numpy()\n",
    "train_x = df_all.drop(columns=['Freedom']).iloc[:, 4:]\n",
    "test_y = df2020['Freedom'].to_numpy()\n",
    "test_x = df2020.drop(columns=['Freedom']).iloc[:, 3:8]\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "limiting-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "hyp_fre = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "generic-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...\t 0.3020329165732277\n",
      "Variance explained...\t 0.34587174347434957\n",
      "Mean squared error...\t 0.013600444882096191\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_y, hyp_fre)\n",
    "var = explained_variance_score(test_y, hyp_fre)\n",
    "mse = mean_squared_error(test_y, hyp_fre)\n",
    "print('R2 score...\\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-profession",
   "metadata": {},
   "source": [
    "### Perceptions of corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "electric-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_all['Perceptions of corruption'].to_numpy()\n",
    "train_x = df_all.drop(columns=['Perceptions of corruption']).iloc[:, 4:]\n",
    "test_y = df2020['Perceptions of corruption'].to_numpy()\n",
    "test_x = df2020.drop(columns=['Perceptions of corruption']).iloc[:, 3:8]\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "abandoned-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "hyp_per = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "corresponding-richmond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...\t 0.2765555424876336\n",
      "Variance explained...\t 0.28050303180713676\n",
      "Mean squared error...\t 0.009715280050987927\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_y, hyp_per)\n",
    "var = explained_variance_score(test_y, hyp_per)\n",
    "mse = mean_squared_error(test_y, hyp_per)\n",
    "print('R2 score...\\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-comparative",
   "metadata": {},
   "source": [
    "### Generosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "satisfactory-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df_all['Generosity'].to_numpy()\n",
    "train_x = df_all.drop(columns=['Generosity']).iloc[:, 4:]\n",
    "test_y = df2020['Generosity'].to_numpy()\n",
    "test_x = df2020.drop(columns=['Generosity']).iloc[:, 3:8]\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "separated-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "hyp_gen = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "planned-patrol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...\t -0.008795808338402544\n",
      "Variance explained...\t 0.16812774065605385\n",
      "Mean squared error...\t 0.010294877011567371\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_y, hyp_gen)\n",
    "var = explained_variance_score(test_y, hyp_gen)\n",
    "mse = mean_squared_error(test_y, hyp_gen)\n",
    "print('R2 score...\\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-relation",
   "metadata": {},
   "source": [
    "## Predicting happiness score/rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "decreased-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'GDP per capita':hyp_gdp, 'Social support': hyp_ss, \n",
    "     'Healthy life expectancy': hyp_hle, 'Freedom': hyp_fre, \n",
    "      'Perceptions of corruption': hyp_per, 'Generosity': hyp_gen}\n",
    "df_hyp = pd.DataFrame(data=data) # dataframe of hypothesis # test_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "liable-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hyp.to_numpy()\n",
    "Y = df2020['Score']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "nutritional-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "hyp = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "paperback-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score...\t 0.7396240576013514\n",
      "Variance explained...\t 0.7478980210683996\n",
      "Mean squared error...\t 0.28719154667616514\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(test_y, hyp)\n",
    "var = explained_variance_score(test_y, hyp)\n",
    "mse = mean_squared_error(test_y, hyp)\n",
    "print('R2 score...\\t', r2)\n",
    "print('Variance explained...\\t', var)\n",
    "print('Mean squared error...\\t', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-destination",
   "metadata": {},
   "source": [
    "## Viewing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-sentence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "civic-representative",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Happiness Data Analysis 2015-2019](https://www.kaggle.com/kojisera/happiness-data-analysis-2015-2019) - See top happy 30 countries scatter plot for 2015-2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
